---
layout: default
---
<!-- Posts -->
<ul id="posts">

	{% for post in paginator.posts %}

	  <li class="post">
	    <time datetime="{{ post.date | date_to_xmlschema }}" class="by-line"> <i>{{ post.date | date_to_string }}</i> </time>
	  	<h2><a class="index-post-title" href="{% if site.baseurl == "/" %}{{ post.url }}{% else %}{{ post.url | prepend: site.baseurl }}{% endif %}">{%if post.header %}{{ post.header }}{% else %}{{ post.title }}{% endif %}</a></h2>
	  	<p class="index-excerpt">{{ post.excerpt | remove: '<p>' | remove: '</p>' }}</p>
	  </li>

    {% endfor %}

    <li class="post">
    	<h2><a class="index-post-title" href="https://www.youtube.com/playlist?list=PLYQvRkjCv-_0mj-ArXsPpoBEZUkJX4h4k">Research and Hobby Videos</a></h2>
	  	<p class="index-excerpt">
			<h3>Joint Point Cloud and Image Based Localization For Efficient Inspection in Mixed Reality</h3>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/1EEftDU7BIw" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	<b>Reference:</b>
			M. P. Das, Z. Dong, S. Scherer. <b>Joint Point Cloud and Image Based Localization For Efficient Inspection in Mixed Reality</b>. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, 2018. 
			<br>
			PDF: <a href="https://arxiv.org/pdf/1811.02563.pdf">https://arxiv.org/pdf/1811.02563.pdf</a>
			<br>
			Code: <a href="https://bitbucket.org/castacks/jpil">https://bitbucket.org/castacks/jpil</a>
			<br>
	  		<h3>Augmenting Inspection Capabilities with Mixed-Reality</h3>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/xKZL7sdT6X4" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	We demonstrate the use of mixed-reality headset worn by an inspector on the site of inspection. Such a headset along with the software we have developed, can augment the on-site inspector's capabilities to visualize and interact with digital annotations. Thus allowing precise and clear information about the region of interest.
			<hr><br><br>
	  	</p>

	  	<p class="index-excerpt">
		  	<h3>Demo Run: Thermal, Monocular Vision-Based Localization and Mapping of MAV at Night.</h3>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/SkeRUXWA9OE" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	Video runs at 0.5x. This video demonstrates how the state-of-the-art monocular computer vision algorithms perform in thermal IR domain.
		  	<b>Reference:</b>
			S. Daftry, M. P. Das, J. Delaune, C. Sorice, R. Hewitt, S. Reddy, D. Lytle, E. Gu, L. Matthies. <b>Robust Vision-based Autonomous Navigation, Mapping and Landing for MAVs at Night</b>. International Symposium on Experimental Robotics (ISER), Buenos Aires, 2018. 
			<hr><br><br>
		</p>

	  	<p class="index-excerpt">
	  		<h3>5-DoF Monocular Visual Localization Over Grid Based Floor</h3>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/UZh_jqDBcpA" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/hTMrF5FQ8Uw" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	<b>Reference:</b>
			M. P. Das, G. Gardi, J. Mukhopadhyay. <b>5-DoF Monocular Visual Localization Over Grid Based Floor.</b> IEEE International Conference on Indoor Positioning and Indoor Navigation (IPIN), Sapporo, 2017. 
			<br>
			PDF: <a href="https://ieeexplore.ieee.org/document/8115889">https://ieeexplore.ieee.org/document/8115889</a>
			<br>
			Code: <a href="https://github.com/mpdmanash/mlog_ros">https://github.com/mpdmanash/mlog_ros</a>
			<hr><br><br>
		</p>

	  	<p class="index-excerpt">
	  		<h3>Quadcopter mapping, path planning and controls for Obstacle avoidance.</h3>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/ZjnwAPUFEPk" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	Sensors: 2D Lidar, GPS, IMU<br>
			Flight controller: PX4<br>
			Path planning algorithm: RRT# using OMPL C++ (http://ompl.kavrakilab.org/)<br>
			Other libraries used: FCL (A Flexible Collision Library), Octomap, ROS.<br>
			Simulation is made in Gazebo.
			<hr><br><br>
	  	</p>
	  	<p class="index-excerpt">
	  		<h3>VINS-Mono Visual Inertial Odometry on Optor Stereo Camera</h3>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/oeuvXz2kizM" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/HwLXKSFFrZk" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	Camera and IMU calibration performed using <a href="https://github.com/ethz-asl/kalibr">kalibr</a>
			<hr><br><br>
	  	</p>


	  	<p class="index-excerpt">
	  		<h3>Hobby Aeromodelling</h3>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/vT2XpDCsz9Q" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/tcnGFiVuvJg" frameborder="0" allowfullscreen></iframe> </figure> </div>
		  	<div class="video"> <figure> <iframe width="640" height="480" src="//www.youtube.com/embed/I09s3qx_TlM" frameborder="0" allowfullscreen></iframe> </figure> </div>
			<hr><br><br>
	  	</p>
	 </li>

</ul>